{
 "metadata": {
  "name": "",
  "signature": "sha256:1504698a552e1cf994b0a2f0117be8fa246ed666d8cdb528f14066599124b901"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sys\n",
      "import os\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "from sklearn import ensemble\n",
      "from sklearn import datasets\n",
      "from sklearn.utils import shuffle\n",
      "from sklearn.metrics import mean_squared_error\n",
      "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
      "from sklearn.metrics import mean_squared_error, explained_variance_score, r2_score"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 114
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# read drug training set\n",
      "df = pd.read_csv(r'/Users/smacrae/Documents/specialty/oration-drug.csv', sep=',', \n",
      "                 error_bad_lines=False, \n",
      "                 index_col=False, \n",
      "                 dtype=unicode)\n",
      "\n",
      "# impute null cells with 'f' (for false)\n",
      "df = df.fillna('f')\n",
      "\n",
      "# describe drug tarining set\n",
      "df.describe()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>ndc</th>\n",
        "      <th>brand_name</th>\n",
        "      <th>generic_name</th>\n",
        "      <th>gcn_seq_no</th>\n",
        "      <th>rxcui</th>\n",
        "      <th>manufacturer</th>\n",
        "      <th>purchasing_pattern</th>\n",
        "      <th>strength</th>\n",
        "      <th>therapeutic_class</th>\n",
        "      <th>is_brand</th>\n",
        "      <th>is_generic_available</th>\n",
        "      <th>generic_substitute_rxcui</th>\n",
        "      <th>is_specialty</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>count</th>\n",
        "      <td>      150679</td>\n",
        "      <td> 150679</td>\n",
        "      <td> 150679</td>\n",
        "      <td> 150679</td>\n",
        "      <td> 150679</td>\n",
        "      <td>                   150679</td>\n",
        "      <td> 150679</td>\n",
        "      <td> 150679</td>\n",
        "      <td> 150679</td>\n",
        "      <td> 150679</td>\n",
        "      <td> 150679</td>\n",
        "      <td> 150679</td>\n",
        "      <td> 150679</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>unique</th>\n",
        "      <td>      150679</td>\n",
        "      <td>  13846</td>\n",
        "      <td>  13692</td>\n",
        "      <td>   3941</td>\n",
        "      <td>  13547</td>\n",
        "      <td>                     5399</td>\n",
        "      <td>      3</td>\n",
        "      <td>   3791</td>\n",
        "      <td>      1</td>\n",
        "      <td>      2</td>\n",
        "      <td>      2</td>\n",
        "      <td>   5442</td>\n",
        "      <td>      2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>top</th>\n",
        "      <td> 55154160301</td>\n",
        "      <td>      f</td>\n",
        "      <td> Oxygen</td>\n",
        "      <td>      f</td>\n",
        "      <td>      f</td>\n",
        "      <td> Nelco Laboratories, Inc.</td>\n",
        "      <td>      f</td>\n",
        "      <td>      f</td>\n",
        "      <td>      f</td>\n",
        "      <td>      f</td>\n",
        "      <td>      f</td>\n",
        "      <td>      f</td>\n",
        "      <td>      f</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>freq</th>\n",
        "      <td>           1</td>\n",
        "      <td> 115154</td>\n",
        "      <td>   2959</td>\n",
        "      <td>  69766</td>\n",
        "      <td>  23252</td>\n",
        "      <td>                     9448</td>\n",
        "      <td>  80722</td>\n",
        "      <td>  23252</td>\n",
        "      <td> 150679</td>\n",
        "      <td> 127998</td>\n",
        "      <td> 130057</td>\n",
        "      <td> 130057</td>\n",
        "      <td> 131073</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 115,
       "text": [
        "                ndc brand_name generic_name gcn_seq_no   rxcui  \\\n",
        "count        150679     150679       150679     150679  150679   \n",
        "unique       150679      13846        13692       3941   13547   \n",
        "top     55154160301          f       Oxygen          f       f   \n",
        "freq              1     115154         2959      69766   23252   \n",
        "\n",
        "                    manufacturer purchasing_pattern strength  \\\n",
        "count                     150679             150679   150679   \n",
        "unique                      5399                  3     3791   \n",
        "top     Nelco Laboratories, Inc.                  f        f   \n",
        "freq                        9448              80722    23252   \n",
        "\n",
        "       therapeutic_class is_brand is_generic_available  \\\n",
        "count             150679   150679               150679   \n",
        "unique                 1        2                    2   \n",
        "top                    f        f                    f   \n",
        "freq              150679   127998               130057   \n",
        "\n",
        "       generic_substitute_rxcui is_specialty  \n",
        "count                    150679       150679  \n",
        "unique                     5442            2  \n",
        "top                           f            f  \n",
        "freq                     130057       131073  "
       ]
      }
     ],
     "prompt_number": 115
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pd.Series(df.columns).tolist()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 116,
       "text": [
        "['ndc',\n",
        " 'brand_name',\n",
        " 'generic_name',\n",
        " 'gcn_seq_no',\n",
        " 'rxcui',\n",
        " 'manufacturer',\n",
        " 'purchasing_pattern',\n",
        " 'strength',\n",
        " 'therapeutic_class',\n",
        " 'is_brand',\n",
        " 'is_generic_available',\n",
        " 'generic_substitute_rxcui',\n",
        " 'is_specialty']"
       ]
      }
     ],
     "prompt_number": 116
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# initialize label encoders for each variable\n",
      "encode_gcn_seq_no = LabelEncoder()\n",
      "encode_manufacturer = LabelEncoder()\n",
      "encode_purchasing_pattern = LabelEncoder()\n",
      "encode_is_brand = LabelEncoder()\n",
      "encode_is_generic_available = LabelEncoder()\n",
      "encode_is_specialty = LabelEncoder()\n",
      "\n",
      "# gcn_seq_no\n",
      "factor_gcn_seq_no = encode_gcn_seq_no.fit(df['gcn_seq_no'])\n",
      "df['gcn_seq_no_factor'] = factor_gcn_seq_no.transform(df['gcn_seq_no'])\n",
      "\n",
      "# manufacturer\n",
      "factor_manufacturer = encode_manufacturer.fit(df['manufacturer'])\n",
      "df['manufacturer_factor'] = factor_manufacturer.transform(df['manufacturer'])\n",
      "\n",
      "# purchasing_pattern\n",
      "factor_purchasing_pattern = encode_purchasing_pattern.fit(df['purchasing_pattern'])\n",
      "df['purchasing_pattern_factor'] = factor_purchasing_pattern.transform(df['purchasing_pattern'])\n",
      "\n",
      "# is_brand\n",
      "factor_is_brand = encode_is_brand.fit(df['is_brand'])\n",
      "df['is_brand_factor'] = factor_is_brand.transform(df['is_brand'])\n",
      "\n",
      "# is_generic\n",
      "factor_is_generic_available = encode_is_generic_available.fit(df['is_generic_available'])\n",
      "df['is_generic_available_factor'] = factor_is_generic_available.transform(df['is_generic_available'])\n",
      "\n",
      "# is_specialty\n",
      "factor_is_specialty = encode_is_specialty.fit(df['is_specialty'])\n",
      "df['is_specialty_factor'] = factor_is_specialty.transform(df['is_specialty'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 57
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# define model signals\n",
      "signals = ['gcn_seq_no_factor',\n",
      "         'manufacturer_factor',\n",
      "         'purchasing_pattern_factor',\n",
      "         'is_brand_factor',\n",
      "         'is_generic_available_factor']\n",
      "\n",
      "# define model target\n",
      "target = 'is_specialty_factor'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 58
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# shuffle df\n",
      "X, y = shuffle(df[signals], df[target], random_state=13)\n",
      "\n",
      "# create training/test sets\n",
      "X = X.astype(np.float32)\n",
      "offset = int(X.shape[0] * 0.9)\n",
      "X_train, y_train = X[:offset], y[:offset]\n",
      "X_test, y_test = X[offset:], y[offset:]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 81
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# define model parameters\n",
      "gbm_params = {'n_estimators': 1000, 'max_depth': len(signals), 'min_samples_split': 5, 'subsample': 0.70,\n",
      "          'learning_rate': 0.01, 'loss': 'deviance', 'verbose': 1}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 82
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# train model\n",
      "gbm = ensemble.GradientBoostingClassifier(**gbm_params)\n",
      "gbm.fit(X_train, y_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "      Iter       Train Loss      OOB Improve   Remaining Time \n",
        "         1           0.7613           0.0144            1.98m"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         2           0.7458           0.0135            1.73m"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         3           0.7343           0.0125            1.63m"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         4           0.7210           0.0119            1.60m"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         5           0.7070           0.0114            1.57m"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         6           0.6976           0.0109            1.56m"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         7           0.6876           0.0103            1.54m"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         8           0.6758           0.0098            1.53m"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         9           0.6683           0.0094            1.51m"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "        10           0.6563           0.0111            1.52m"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "        20           0.5847           0.0063            1.49m"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "        30           0.5294           0.0049            1.49m"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "        40           0.4870           0.0038            1.48m"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "        50           0.4514           0.0032            1.48m"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "        60           0.4204           0.0026            1.47m"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "        70           0.3922           0.0023            1.47m"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "        80           0.3714           0.0019            1.46m"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "        90           0.3510           0.0017            1.44m"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "       100           0.3353           0.0015            1.43m"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "       200           0.2330           0.0007            1.29m"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "       300           0.1896           0.0002            1.13m"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "       400           0.1552           0.0004           58.38s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "       500           0.1359           0.0001           48.81s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "       600           0.1212           0.0001           39.01s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "       700           0.1126           0.0001           29.25s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "       800           0.1037           0.0000           19.50s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "       900           0.0958           0.0000            9.74s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "      1000           0.0900           0.0000            0.00s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "gross_cost R-squared: 0.8798"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 83
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# calculate GBRT Feature Importances\n",
      "\n",
      "# Select feature importances\n",
      "# gross_cost\n",
      "feature_importance_gbrt = gbm.feature_importances_\n",
      "\n",
      "# gross_cost\n",
      "feature_importance_gbrt = 100.0 * (feature_importance_gbrt / feature_importance_gbrt.max())\n",
      "sorted_idx_gbrt = np.argsort(feature_importance_gbrt)\n",
      "pos_gbrt = np.arange(sorted_idx_gbrt.shape[0]) + .5\n",
      "\n",
      "# gross_cost\n",
      "feature_names_gbrt = pd.DataFrame(gbm.feature_importances_,\n",
      "                                  signals).sort([0], ascending=True).index.values\n",
      "\n",
      "plt.barh(pos_gbrt, feature_importance_gbrt[sorted_idx_gbrt], align='center')\n",
      "plt.yticks(pos_gbrt, feature_names_gbrt)\n",
      "plt.xlabel('Relative Influence')\n",
      "plt.title(target[0])\n",
      "\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 111
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "results = pd.concat([pd.Series(y_test), pd.Series(gbm.predict(X_test))], axis=1)\n",
      "results.columns = ['Actual','Predicted']\n",
      "\n",
      "positive = []\n",
      "for i in results.index:\n",
      "    if (results.loc[i,'Actual'] == 1) & (results.loc[i,'Predicted'] == 1):\n",
      "        positive.append(1)\n",
      "    else:\n",
      "        positive.append(0)\n",
      "        \n",
      "false_positive = []\n",
      "for i in results.index:\n",
      "    if (results.loc[i,'Actual'] == 0) & (results.loc[i,'Predicted'] == 1):\n",
      "        false_positive.append(1)\n",
      "    else:\n",
      "        false_positive.append(0)\n",
      "        \n",
      "negative = []\n",
      "for i in results.index:\n",
      "    if (results.loc[i,'Actual'] == 0) & (results.loc[i,'Predicted'] == 0):\n",
      "        negative.append(1)\n",
      "    else:\n",
      "        negative.append(0)\n",
      "        \n",
      "false_negative = []\n",
      "for i in results.index:\n",
      "    if (results.loc[i,'Actual'] == 1) & (results.loc[i,'Predicted'] == 0):\n",
      "        false_negative.append(1)\n",
      "    else:\n",
      "        false_negative.append(0)\n",
      "        \n",
      "results['Positive'] = positive\n",
      "results['False_Positive'] = false_positive\n",
      "results['Negative'] = negative\n",
      "results['False_Negative'] = false_negative"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 106
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'Classifier Accuracy:', np.round((results['Negative'].sum() + results['Positive'].sum())/1.0/len(results),4),'\\n'\n",
      "print 'Classification Results:','\\n', results[['Negative','Positive','False_Negative','False_Positive']].sum()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Classifier Accuracy: 0.9862 \n",
        "\n",
        "Classification Results: \n",
        "Negative          13109\n",
        "Positive           1751\n",
        "False_Negative      207\n",
        "False_Positive        1\n",
        "dtype: int64\n"
       ]
      }
     ],
     "prompt_number": 109
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}